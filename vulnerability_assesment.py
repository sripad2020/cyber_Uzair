import asyncio
import os
import socket
import ssl
import json
import uuid
import time
from datetime import datetime
from typing import Dict, List, Optional
from concurrent.futures import ThreadPoolExecutor
import aiohttp
import nmap
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import re
from OpenSSL import crypto
import subprocess

def make_json_serializable(obj):
    """Recursively convert non-JSON-serializable objects to serializable formats."""
    if isinstance(obj, bytes):
        return obj.decode('utf-8', errors='ignore')
    elif isinstance(obj, (list, tuple)):
        return [make_json_serializable(item) for item in obj]
    elif isinstance(obj, dict):
        return {
            make_json_serializable(k): make_json_serializable(v)
            for k, v in obj.items()
        }
    elif isinstance(obj, (set, frozenset)):
        return list(obj)
    return obj

async def perform_vulnerability_assessment(
        target: str,
        scan_id: str,
        testssl_path: str = "testssl.sh",
        output_dir: str = "scan_results"
) -> Dict:
    """Perform an advanced vulnerability assessment with Nmap, HTTP headers, SSL/TLS analysis, and web vulnerability scanning mimicking Burp Suite."""

    # Initialize result dictionary
    result = {
        'target': target,
        'timestamp': datetime.utcnow().isoformat(),
        'target_ip': None,
        'open_ports': [],
        'services': {},
        'http_headers': {},
        'ssl_info': {},
        'nmap_vuln_info': [],
        'web_vulnerabilities': [],
        'vulnerabilities': [],
        'vulners_scan': {},
        'mitigations': {}
    }
    executor = ThreadPoolExecutor(max_workers=10)
    os.makedirs(output_dir, exist_ok=True)

    # Resolve target to IP address
    try:
        target = target.replace('http://', '').replace('https://', '').split('/')[0]
        try:
            target_ip = await asyncio.get_event_loop().run_in_executor(
                executor, socket.gethostbyname, target
            )
            result['target_ip'] = target_ip
        except socket.gaierror:
            result = {'error': f'Could not resolve {target} to an IP address', 'error_type': 'ResolutionError'}
            with open(os.path.join(output_dir, f'{scan_id}.json'), 'w') as f:
                json.dump(result, f)
            return result
    except Exception as e:
        result = {'error': f'Invalid target: {str(e)}', 'error_type': 'ValidationError'}
        with open(os.path.join(output_dir, f'{scan_id}.json'), 'w') as f:
            json.dump(result, f)
        return result

    # Asynchronous port scanning and service detection
    async def scan_ports(ports: List[int] = None) -> None:
        if ports is None:
            ports = [21, 22, 23, 25, 53, 80, 110, 143, 443, 445, 3389, 8080, 8443]

        async def check_port(ip: str, port: int) -> Optional[Dict]:
            try:
                conn = asyncio.open_connection(ip, port)
                reader, _ = await asyncio.wait_for(conn, timeout=2)
                reader.close()
                return {'port': port, 'state': 'open'}
            except:
                return None

        tasks = [check_port(target_ip, port) for port in ports]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        result['open_ports'] = [r['port'] for r in results if r and isinstance(r, dict)]

        # Service detection and vulnerability scanning using nmap with Vulners
        try:
            nm = nmap.PortScanner()
            port_list = ','.join(map(str, result['open_ports']))
            nm.scan(target_ip, arguments=f'-sV --script=vulners -p{port_list}')
            for host in nm.all_hosts():
                for port in nm[host].all_tcp():
                    service = nm[host]['tcp'][port]
                    result['services'][port] = {
                        'name': service.get('name', 'unknown'),
                        'product': service.get('product', ''),
                        'version': service.get('version', ''),
                        'banner': service.get('extrainfo', '')
                    }
                    if 'script' in service and 'vulners' in service['script']:
                        result['nmap_vuln_info'].append({
                            'port': port,
                            'script': 'vulners',
                            'output': service['script']['vulners'],
                            'service': f"{service.get('product', '')} {service.get('version', '')}".strip()
                        })
                        for line in service['script']['vulners'].splitlines():
                            if 'CVE-' in line:
                                parts = line.split()
                                cve_id = next((p for p in parts if p.startswith('CVE-')), 'Unknown')
                                score = next((p for p in parts if p.replace('.', '').isdigit()), '0.0')
                                result['vulnerabilities'].append({
                                    'type': 'nmap_vuln',
                                    'cve_id': cve_id,
                                    'details': f"{cve_id} found for {service.get('product', 'unknown')} on port {port}",
                                    'severity': 'critical' if float(score) >= 9 else 'high' if float(score) >= 7 else 'medium' if float(score) >= 4 else 'low',
                                    'cvss_score': float(score),
                                    'mitigation': f"Update {service.get('product', 'software')} to the latest version or apply vendor patches for {cve_id}."
                                })
        except Exception as e:
            result['services']['error'] = f"Nmap scan failed: {str(e)}"

    # Fetch and analyze HTTP headers
    async def fetch_http_headers(timeout: int = 5) -> None:
        async with aiohttp.ClientSession() as session:
            for scheme in ['http', 'https']:
                try:
                    async with session.get(f"{scheme}://{target}", timeout=timeout) as resp:
                        headers = dict(resp.headers)
                        result['http_headers'][scheme] = headers
                        security_headers = [
                            'Content-Security-Policy',
                            'X-Frame-Options',
                            'Strict-Transport-Security',
                            'X-Content-Type-Options',
                            'X-XSS-Protection',
                            'Referrer-Policy'
                        ]
                        missing_headers = [h for h in security_headers if h not in headers]
                        if missing_headers:
                            result['vulnerabilities'].append({
                                'type': 'missing_security_headers',
                                'details': f"Missing headers for {scheme}: {', '.join(missing_headers)}",
                                'severity': 'medium',
                                'mitigation': f"Implement missing headers: {', '.join(missing_headers)}. Example: Content-Security-Policy: default-src 'self';"
                            })

                        # Check for insecure cookies
                        if 'Set-Cookie' in headers:
                            cookies = headers['Set-Cookie']
                            if 'Secure' not in cookies:
                                result['vulnerabilities'].append({
                                    'type': 'insecure_cookie',
                                    'details': f"Non-secure cookie detected in {scheme} response",
                                    'severity': 'medium',
                                    'mitigation': "Set the 'Secure' flag on cookies to ensure they are only sent over HTTPS."
                                })
                            if 'HttpOnly' not in cookies:
                                result['vulnerabilities'].append({
                                    'type': 'insecure_cookie',
                                    'details': f"Cookie without HttpOnly flag in {scheme} response",
                                    'severity': 'medium',
                                    'mitigation': "Set the 'HttpOnly' flag to prevent client-side script access to cookies."
                                })

                        # Check CORS configuration
                        if 'Access-Control-Allow-Origin' in headers:
                            cors = headers['Access-Control-Allow-Origin']
                            if cors == '*':
                                result['vulnerabilities'].append({
                                    'type': 'insecure_cors',
                                    'details': f"Overly permissive CORS policy ({cors}) in {scheme} response",
                                    'severity': 'medium',
                                    'mitigation': "Restrict CORS to specific trusted domains instead of using '*'."
                                })
                except Exception as e:
                    result['http_headers'][scheme] = {'error': f"HTTP fetch failed: {str(e)}"}

    # Perform advanced SSL/TLS analysis with testssl.sh
    async def analyze_ssl() -> None:
        try:
            if not os.path.exists(testssl_path):
                result['ssl_info'] = {'error': 'testssl.sh not found at specified path'}
                return

            output_file = os.path.join(output_dir, f"testssl_{scan_id}.json")
            cmd = [testssl_path, "--jsonfile-pretty", output_file, "--quiet", f"{target}:443"]
            process = await asyncio.create_subprocess_exec(*cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
            stdout, stderr = await process.communicate()

            if process.returncode != 0:
                result['ssl_info'] = {'error': f"testssl.sh failed: {stderr.decode('utf-8', errors='ignore')}"}
                return

            try:
                with open(output_file, 'r') as f:
                    testssl_results = json.load(f)
                ssl_info = {
                    'cipher': testssl_results.get('preferred_cipher', 'Unknown'),
                    'protocols': testssl_results.get('protocols', []),
                    'vulnerabilities': testssl_results.get('vulnerabilities', []),
                    'certificate': {
                        'issuer': testssl_results.get('issuer', 'Unknown'),
                        'valid_from': testssl_results.get('notBefore', 'Unknown'),
                        'valid_to': testssl_results.get('notAfter', 'Unknown'),
                        'serial': testssl_results.get('serialNumber', 'Unknown')
                    }
                }
                result['ssl_info'] = ssl_info

                insecure_protocols = ['SSLv2', 'SSLv3', 'TLS1', 'TLS1_1']
                for proto in ssl_info['protocols']:
                    if proto in insecure_protocols:
                        result['vulnerabilities'].append({
                            'type': 'insecure_tls_version',
                            'details': f"Using outdated {proto}",
                            'severity': 'high',
                            'mitigation': f"Disable {proto} and enable only TLS 1.2 or higher."
                        })

                expiry_date = ssl_info['certificate'].get('valid_to')
                if expiry_date:
                    try:
                        expiry = datetime.strptime(expiry_date, '%Y-%m-%d %H:%M:%S')
                        if expiry < datetime.utcnow():
                            result['vulnerabilities'].append({
                                'type': 'expired_certificate',
                                'details': f"Certificate expired on {expiry_date}",
                                'severity': 'high',
                                'mitigation': "Renew the SSL/TLS certificate immediately."
                            })
                    except ValueError:
                        pass

                for vuln in ssl_info['vulnerabilities']:
                    severity = vuln.get('severity', 'unknown').lower()
                    result['vulnerabilities'].append({
                        'type': 'ssl_vuln',
                        'details': vuln.get('finding', 'Unknown vulnerability'),
                        'severity': severity if severity in ['low', 'medium', 'high', 'critical'] else 'unknown',
                        'mitigation': f"Review and apply patches for {vuln.get('finding', 'the SSL vulnerability')}."
                    })
            except Exception as e:
                result['ssl_info'] = {'error': f"Failed to parse testssl.sh output: {str(e)}"}
            finally:
                if os.path.exists(output_file):
                    os.remove(output_file)
        except Exception as e:
            result['ssl_info'] = {'error': f"SSL analysis failed: {str(e)}"}

    # Web vulnerability scanning (mimicking Burp Suite)
    async def scan_web_vulnerabilities() -> None:
        async with aiohttp.ClientSession() as session:
            try:
                # Basic web crawling
                urls = [f"https://{target}", f"http://{target}"]
                visited = set()
                forms = []
                max_depth = 2

                async def crawl(url: str, depth: int = 0):
                    if depth > max_depth or url in visited:
                        return
                    visited.add(url)
                    try:
                        async with session.get(url, timeout=5) as resp:
                            if resp.status != 200:
                                return
                            content = await resp.text()
                            soup = BeautifulSoup(content, 'html.parser')

                            # Find forms for potential vulnerabilities
                            for form in soup.find_all('form'):
                                action = form.get('action')
                                if action:
                                    form_url = urljoin(url, action)
                                    inputs = [inp.get('name') for inp in form.find_all('input') if inp.get('name')]
                                    forms.append({'url': form_url, 'inputs': inputs})

                            # Find links to crawl
                            for a in soup.find_all('a', href=True):
                                next_url = urljoin(url, a['href'])
                                if urlparse(next_url).netloc == urlparse(url).netloc:
                                    await crawl(next_url, depth + 1)
                    except Exception:
                        pass

                # Start crawling
                for url in urls:
                    await crawl(url)

                # Test for XSS (simplified by checking reflected input)
                for form in forms:
                    form_url = form['url']
                    for input_name in form['inputs']:
                        payload = "<script>alert('xss')</script>"
                        try:
                            async with session.post(form_url, data={input_name: payload}, timeout=5) as resp:
                                content = await resp.text()
                                if payload in content:
                                    result['web_vulnerabilities'].append({
                                        'type': 'xss',
                                        'details': f"Reflected XSS detected in form at {form_url} with input {input_name}",
                                        'severity': 'high',
                                        'mitigation': "Implement input sanitization and output encoding. Use a Content Security Policy (CSP)."
                                    })
                        except Exception:
                            pass

                # Test for SQL Injection (simplified by checking error patterns)
                sql_payloads = ["' OR '1'='1", "1; DROP TABLE users --"]
                for form in forms:
                    form_url = form['url']
                    for input_name in form['inputs']:
                        for payload in sql_payloads:
                            try:
                                async with session.post(form_url, data={input_name: payload}, timeout=5) as resp:
                                    content = await resp.text()
                                    if re.search(r"(sql|mysql|database|syntax|error)", content, re.IGNORECASE):
                                        result['web_vulnerabilities'].append({
                                            'type': 'sql_injection',
                                            'details': f"Potential SQL injection in form at {form_url} with input {input_name}",
                                            'severity': 'critical',
                                            'mitigation': "Use parameterized queries or prepared statements. Validate and sanitize all inputs."
                                        })
                            except Exception:
                                pass

                # Check for directory traversal
                traversal_payloads = ["../../etc/passwd", "../../windows/win.ini"]
                for url in urls:
                    for payload in traversal_payloads:
                        test_url = f"{url}/{payload}"
                        try:
                            async with session.get(test_url, timeout=5) as resp:
                                content = await resp.text()
                                if "root:" in content or "[extensions]" in content:
                                    result['web_vulnerabilities'].append({
                                        'type': 'directory_traversal',
                                        'details': f"Directory traversal vulnerability at {test_url}",
                                        'severity': 'high',
                                        'mitigation': "Sanitize and validate file path inputs. Restrict file access to intended directories."
                                    })
                        except Exception:
                            pass

                # Check for CSRF token absence
                for form in forms:
                    try:
                        async with session.get(form['url'], timeout=5) as resp:
                            if resp.status != 200:
                                continue
                            content = await resp.text()
                            soup = BeautifulSoup(content, 'html.parser')
                            form_elem = soup.find('form', action=form['url'].split('/')[-1])
                            if form_elem and not any(form_elem.find('input', {'name': name, 'type': 'hidden'}) for name in ['csrf', 'token', '_token']):
                                result['web_vulnerabilities'].append({
                                    'type': 'csrf',
                                    'details': f"Missing CSRF token in form at {form['url']}",
                                    'severity': 'medium',
                                    'mitigation': "Implement CSRF tokens for all state-changing forms."
                                })
                    except Exception:
                        pass

            except Exception as e:
                result['web_vulnerabilities'].append({
                    'type': 'web_scan_error',
                    'details': f"Web vulnerability scan failed: {str(e)}",
                    'severity': 'unknown',
                    'mitigation': "Ensure the target is accessible and retry the scan."
                })

    # Run all scans concurrently
    try:
        tasks = [
            scan_ports(),
            fetch_http_headers(),
            analyze_ssl(),
            scan_web_vulnerabilities()
        ]
        await asyncio.gather(*tasks)
    except Exception as e:
        result['error'] = f"Scan execution failed: {str(e)}"
        result['error_type'] = 'ScanError'

    # Convert result to JSON-serializable format
    result = make_json_serializable(result)

    # Save results
    output_path = os.path.join(output_dir, f"{scan_id}.json")
    with open(output_path, 'w') as f:
        json.dump(result, f, indent=4)

    return result

if __name__ == "__main__":
    async def main():
        scan_id = str(uuid.uuid4())
        result = await perform_vulnerability_assessment("example.com", scan_id)
        print(json.dumps(result, indent=4))

    asyncio.run(main())
